{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMAFWKHIJdizBs/8JvSQjdk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"KI3U8XskmWxC","executionInfo":{"status":"ok","timestamp":1760690708668,"user_tz":-120,"elapsed":59987,"user":{"displayName":"Elizabeth Mwangi","userId":"16367964841685849676"}},"outputId":"b4656fd2-ffa3-47f3-f083-74d59b4675a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n","Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly) (8.5.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-c4c7d91a-6715-4d43-a992-87103711486b\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-c4c7d91a-6715-4d43-a992-87103711486b\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving test_predictions (3).csv to test_predictions (3) (1).csv\n","Saving dev_predictions (3).csv to dev_predictions (3) (1).csv\n","Saving dev_predictions (2).csv to dev_predictions (2) (1).csv\n","Saving test_predictions (2).csv to test_predictions (2) (1).csv\n","Saving test_predictions (1).csv to test_predictions (1) (1).csv\n","Saving dev_predictions (1).csv to dev_predictions (1) (1).csv\n","Saving test_predictions.csv to test_predictions (4).csv\n","Saving dev_predictions.csv to dev_predictions (4).csv\n","Uploaded files:\n","- test_predictions (3) (1).csv\n","- dev_predictions (3) (1).csv\n","- dev_predictions (2) (1).csv\n","- test_predictions (2) (1).csv\n","- test_predictions (1) (1).csv\n","- dev_predictions (1) (1).csv\n","- test_predictions (4).csv\n","- dev_predictions (4).csv\n","\n","Preview of dev_predictions.csv:\n","  speaker_id                                          reference  \\\n","0     KES004  it seems like some some fish or some seafood i...   \n","1     KES004  maybe it is kinda some milk or some some some ...   \n","2     KES004  it s a cake of course but am not a good fan of...   \n","3     KES004  evening walks maybe around the city or in the ...   \n","4     KES004  maasai culture of course you will find them do...   \n","\n","                                          prediction       wer  word_accuracy  \\\n","0  It seems like some some some some some some so...  7.933333    -693.333333   \n","1  Maybe it is kind of some meal or some some som...  3.774194    -277.419355   \n","2  It‚Äôs a cake of course but I‚Äôm not a fan of cak...  0.375000      62.500000   \n","3  Evening walks maybe, around the city or in the...  0.242424      75.757576   \n","4  Maasai culture of course you you you will find...  0.382353      61.764706   \n","\n","   lattescore_meaning_preserved gender    age    severity_speech_impairment  \\\n","0                             0   Male  25-30  Severe (frequent breakdowns)   \n","1                             0   Male  25-30  Severe (frequent breakdowns)   \n","2                             0   Male  25-30  Severe (frequent breakdowns)   \n","3                             1   Male  25-30  Severe (frequent breakdowns)   \n","4                             0   Male  25-30  Severe (frequent breakdowns)   \n","\n","             type_nonstandard_speech               etiology  \n","0  Stuttering (Disfluency Disorders)  Neurological disorder  \n","1  Stuttering (Disfluency Disorders)  Neurological disorder  \n","2  Stuttering (Disfluency Disorders)  Neurological disorder  \n","3  Stuttering (Disfluency Disorders)  Neurological disorder  \n","4  Stuttering (Disfluency Disorders)  Neurological disorder  \n","\n","Preview of test_predictions.csv:\n","  speaker_id                                          reference  \\\n","0     KES001  like a four star five star restaurant an appet...   \n","1     KES001  oh yeah serve me some pizza pepperoni pizza pi...   \n","2     KES001  think everyone s ok most people s favourite a ...   \n","3     KES001  that is fish fried fish served with lovely sau...   \n","4     KES001  hindu this is a ceremony like a ceremony but y...   \n","\n","                                          prediction       wer  word_accuracy  \\\n","0  Like a four star five star restaurant a party ...  0.363636      63.636364   \n","1  I love meals some pizza, favorite oil pizza, p...  0.481481      51.851852   \n","2  I think everyone's economy people should prefe...  0.428571      57.142857   \n","3  There is fish fry fish done with the labi sauc...  0.531250      46.875000   \n","4  India this is a ceremony like a ceremony banan...  0.358974      64.102564   \n","\n","   lattescore_meaning_preserved  gender    age    severity_speech_impairment  \\\n","0                             0  Female  30-40  Severe (frequent breakdowns)   \n","1                             0  Female  30-40  Severe (frequent breakdowns)   \n","2                             0  Female  30-40  Severe (frequent breakdowns)   \n","3                             0  Female  30-40  Severe (frequent breakdowns)   \n","4                             0  Female  30-40  Severe (frequent breakdowns)   \n","\n","  type_nonstandard_speech        etiology  \n","0              Dysarthria  Cerebral Palsy  \n","1              Dysarthria  Cerebral Palsy  \n","2              Dysarthria  Cerebral Palsy  \n","3              Dysarthria  Cerebral Palsy  \n","4              Dysarthria  Cerebral Palsy  \n"]}],"source":["# üêæ Install required packages (already installed, but kept for safety)\n","!pip install pandas matplotlib seaborn plotly\n","\n","# üê± Upload your CSV files directly\n","from google.colab import files\n","uploaded = files.upload()\n","\n","# üß∂ Load your data\n","import pandas as pd\n","\n","# Check what files were uploaded\n","print(\"Uploaded files:\")\n","for filename in uploaded.keys():\n","    print(f\"- {filename}\")\n","\n","# üêæ Load CSV data (adjust filenames if needed)\n","# Use the actual filenames from the uploaded list\n","df_dev = pd.read_csv('dev_predictions.csv')\n","df_test = pd.read_csv('test_predictions.csv')\n","\n","# üêà Display first few rows to confirm loading\n","print(\"\\nPreview of dev_predictions.csv:\")\n","print(df_dev.head())\n","\n","print(\"\\nPreview of test_predictions.csv:\")\n","print(df_test.head())\n"]},{"cell_type":"code","source":["print(df_combined.columns.tolist())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7NqPcPwjXEk0","executionInfo":{"status":"ok","timestamp":1760690985818,"user_tz":-120,"elapsed":472,"user":{"displayName":"Elizabeth Mwangi","userId":"16367964841685849676"}},"outputId":"f418a54c-eba1-4e64-ccc7-5634243d436f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["['speaker_id', 'reference', 'prediction', 'wer', 'word_accuracy', 'lattescore_meaning_preserved', 'gender', 'age', 'severity_speech_impairment', 'type_nonstandard_speech', 'etiology', 'model', 'language']\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","from collections import Counter\n","\n","# üêæ Load your CSV files (adjust names to match what you uploaded)\n","df_small_en = pd.read_csv('dev_predictions.csv')\n","df_large_en = pd.read_csv('test_predictions.csv')\n","df_small_sw = pd.read_csv('dev_predictions.csv')\n","df_large_sw = pd.read_csv('test_predictions.csv')\n","\n","# üê± Add model type and language columns\n","df_small_en['model'] = 'Small'\n","df_large_en['model'] = 'Large'\n","df_small_en['language'] = 'English'\n","df_large_en['language'] = 'English'\n","\n","df_small_sw['model'] = 'Small'\n","df_large_sw['model'] = 'Large'\n","df_small_sw['language'] = 'Swahili'\n","df_large_sw['language'] = 'Swahili'\n","\n","# üß∂ Combine datasets\n","df_combined = pd.concat([df_small_en, df_large_en, df_small_sw, df_large_sw], ignore_index=True)\n","\n","# 1. üêæ Overall Meaning Preservation by Language and Model\n","def plot_overall_meaning_preservation(df):\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n","\n","    # Plot 1: Overall comparison by language and model\n","    overall_stats = df.groupby(['language', 'model'])['lattescore_meaning_preserved'].value_counts(normalize=True).unstack()\n","    overall_stats.plot(kind='bar', ax=ax1, color=['green', 'orange', 'red'])\n","    ax1.set_title('Meaning Preservation by Language and Model')\n","    ax1.set_ylabel('Percentage')\n","    ax1.legend(title='LATTES Meaning Levels')\n","    ax1.tick_params(axis='x', rotation=45)\n","\n","    # Plot 2: Meaning preserved vs lost by language and model\n","    preserved_stats = df.groupby(['language', 'model']).apply(\n","        lambda x: (x['lattescore_meaning_preserved'] <= 1).mean(), include_groups=False\n","    ).unstack()\n","    preserved_stats.plot(kind='bar', ax=ax2, color=['blue', 'green', 'red', 'purple'])\n","    ax2.set_title('Percentage of Meaning Preserved (0+1) by Language and Model')\n","    ax2.set_ylabel('Percentage')\n","    ax2.legend(title='Model')\n","    ax2.tick_params(axis='x', rotation=45)\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","plot_overall_meaning_preservation(df_combined)\n","\n","# 2. üêæ Analysis by Severity\n","def plot_by_severity(df):\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n","\n","    # English models by severity\n","    english_data = df[df['language'] == 'English']\n","    if not english_data.empty:\n","        severity_en = english_data.groupby(['model', 'severity_speech_impairment'])['lattescore_meaning_preserved'].mean().unstack()\n","        severity_en.T.plot(kind='bar', ax=ax1, color=['red', 'blue'])\n","        ax1.set_title('English: Average LATTES Score by Severity and Model (Lower = Better)')\n","        ax1.set_ylabel('Average LATTES Score')\n","        ax1.set_xlabel('Severity Level')\n","        ax1.legend(title='Model')\n","        ax1.tick_params(axis='x', rotation=45)\n","\n","    # Swahili models by severity\n","    swahili_data = df[df['language'] == 'Swahili']\n","    if not swahili_data.empty:\n","        severity_sw = swahili_data.groupby(['model', 'severity_speech_impairment'])['lattescore_meaning_preserved'].mean().unstack()\n","        severity_sw.T.plot(kind='bar', ax=ax2, color=['red', 'blue'])\n","        ax2.set_title('Swahili: Average LATTES Score by Severity and Model (Lower = Better)')\n","        ax2.set_ylabel('Average LATTES Score')\n","        ax2.set_xlabel('Severity Level')\n","        ax2.legend(title='Model')\n","        ax2.tick_params(axis='x', rotation=45)\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","plot_by_severity(df_combined)\n","\n","# 3. üêæ Analysis by Etiology\n","def plot_by_etiology(df):\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n","\n","    # English models by etiology\n","    english_data = df[df['language'] == 'English']\n","    if not english_data.empty:\n","        etiology_en = english_data.groupby(['model', 'etiology'])['lattescore_meaning_preserved'].mean().unstack()\n","        etiology_en.T.plot(kind='bar', ax=ax1, color=['red', 'blue'])\n","        ax1.set_title('English: Average LATTES Score by Etiology and Model (Lower = Better)')\n","        ax1.set_ylabel('Average LATTES Score')\n","        ax1.set_xlabel('Etiology')\n","        ax1.legend(title='Model')\n","        ax1.tick_params(axis='x', rotation=45)\n","\n","    # Swahili models by etiology\n","    swahili_data = df[df['language'] == 'Swahili']\n","    if not swahili_data.empty:\n","        etiology_sw = swahili_data.groupby(['model', 'etiology'])['lattescore_meaning_preserved'].mean().unstack()\n","        etiology_sw.T.plot(kind='bar', ax=ax2, color=['red', 'blue'])\n","        ax2.set_title('Swahili: Average LATTES Score by Etiology and Model (Lower = Better)')\n","        ax2.set_ylabel('Average LATTES Score')\n","        ax2.set_xlabel('Etiology')\n","        ax2.legend(title='Model')\n","        ax2.tick_params(axis='x', rotation=45)\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","plot_by_etiology(df_combined)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"udCHs4ql3u30","executionInfo":{"status":"error","timestamp":1760706929931,"user_tz":-120,"elapsed":5124,"user":{"displayName":"Elizabeth Mwangi","userId":"16367964841685849676"}},"outputId":"279d0f93-db39-4511-fdcb-efd5aa4ba0a2"},"execution_count":1,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'dev_predictions.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3908622118.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# üêæ Load your CSV files (adjust names to match what you uploaded)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf_small_en\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dev_predictions.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdf_large_en\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_predictions.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdf_small_sw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dev_predictions.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dev_predictions.csv'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"XtE1GfinoVis"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_KVqt_x0oVo-"},"execution_count":null,"outputs":[]}]}